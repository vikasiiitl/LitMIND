PDF File Name,Summary_T5,Summary_Gemini,Summary_Gpt4,Summary_Gpt3,Summary_BART
0,a large-scale deep recommendation engine is being developed at pinterest . the algorithm uses efficient random walks and graph convolutions to generate embeddings . the algorithm generates higher-quality recommendations than comparable alternatives .,"Graph Convolutional Neural Networks (GCNs) have been successful for graph-based recommendation systems, but scaling them presents a challenge. Researchers developed PinSage, a GCN algorithm using random walks and graph convolutions to generate item embeddings. PinSage was deployed at Pinterest and trained on a vast graph, delivering better recommendations than alternatives. It represents a significant application of deep graph embeddings and advances web-scale recommender systems powered by graph convolutional architectures.","The paper introduces PinSage, a scalable Graph Convolutional Network deployed at Pinterest for web-scale recommendation, handling billions of items and users. PinSage enhances recommendation quality by integrating efficient random walks with graph convolutions, trained on a massive dataset, outperforming existing deep learning and graph-based methods.","Recent advancements in deep neural networks for graph-structured data have enabled state-of-the-art performance in recommender systems. The development of PinSage, a data-efficient Graph Convolutional Network algorithm, has led to higher-quality recommendations at Pinterest, trained on a massive scale of 7.5 billion examples. This marks a significant step towards scalable web-scale recommender systems.","Graph Convolutional Neural Networks for Web-Scale Recommender SystemsRecent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods"
1,"a market-inspired bidding scheme for the assignment of paper reviews in large academic conferences . we provide an analysis of the incentives of reviewers during the bidding phase, when reviewers have both private costs and some information about the demand","A novel bidding scheme for peer review paper assignments is proposed, where reviewers receive budgets and papers have prices based on demand. The scheme incentivizes sincere bidding, ensuring reviewers receive their preferred papers. Simulations show improved bid distribution and assignment compared to existing methods.","We introduce a market-inspired bidding scheme for assigning peer reviews at academic conferences, analyzing reviewer incentives and proposing a budget-based system where paper prices reflect demand. This approach encourages sincere bidding, optimizing paper assignments. Simulations with real conference data suggest significant improvements in bid distribution and assignment outcomes.","Proposing a market-inspired bidding scheme for paper review assignment in academic conferences, this study analyzes reviewer incentives and behavior. By assigning budgets and prices based on paper demand, reviewers are incentivized to bid sincerely for their preferred papers. Simulations demonstrate significant improvements in bid distribution and assignment outcomes, validating the effectiveness of the proposed scheme.","A Market-Inspired Bidding Scheme for Peer Review Paper AssignmentAbstractWe propose a market-inspired bidding scheme for the assignment of paper reviews in large academic conferences. We provide an analysis of the incentives of reviewers during the bidding phase,"
2,graph neural networks (GNNs) have made great progress in recommendation . existing GNNs cannot distinguish diverse local patterns of each node .,"ApeGNN enhances GNN-based recommenders by introducing node-wise adaptive aggregation. It enables each node to adjust its diffusion weights based on local structure, allowing for more tailored information propagation. Experiments on various datasets demonstrate the superiority of ApeGNN, outperforming existing methods by up to 48.94%, highlighting the value of adaptive aggregation in recommendation.","ApeGNN introduces a node-wise adaptive aggregation mechanism in graph neural networks (GNNs) for enhanced recommendation systems. By allowing each node to adjust its diffusion weights according to local structures, ApeGNN outperforms existing GNN-based methods by up to 48.94% in tests on six recommendation datasets.","""ApeGNN introduces node-wise adaptive aggregation in graph neural networks for recommendation systems. By allowing nodes to adaptively determine diffusion weights based on local structures, ApeGNN outperforms existing GNN-based recommender methods by up to 48.94% in experiments on popular datasets, showcasing the effectiveness of this innovative approach.""","ApeGNN: Node-Wise Adaptive Aggregation in GNNs for RecommendationIn recent years, graph neural networks (GNNs) have made great progress in recommendation. The core mechanism of GNN’"
3,the uncertain compatibility of the two networks puts an extra burden on handcrafted model designs . separate spatial and temporal modeling naturally violates the unified spatiotemporal inter-dependencies in real world .,"FourierGNN, a novel graph neural network architecture, redefines multivariate time series forecasting as predictions on hypervariate graphs. It utilizes Fourier Graph Operator for matrix multiplications in Fourier space, providing high expressiveness and low complexity. This unified spatiotemporal modeling overcomes the limitations of previous methods that separately capture spatial and temporal dependencies. FourierGNN's theoretical equivalence to graph convolutions further validates its effectiveness. Empirical evaluations on seven datasets demonstrate its superior performance, efficiency, and parameter efficiency compared to state-of-the-art approaches.","FourierGNN redefines multivariate time series forecasting by integrating spatial and temporal dynamics into a unified graph model, the hypervariate graph. This novel approach, using Fourier Graph Neural Network architecture, simplifies computations and enhances forecasting accuracy, outperforming traditional methods in extensive tests across multiple datasets.","""FourierGNN revolutionizes multivariate time series forecasting by introducing a pure graph perspective. It defines hypervariate graphs to unify spatial and temporal dynamics, presenting a novel architecture, Fourier Graph Neural Network (FourierGNN), with Fourier Graph Operator (FGO). The approach achieves superior performance, efficiency, and fewer parameters, validated through theoretical analysis and extensive experiments.""",FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph PerspectiveMultivariate time series (MTS) forecasting has shown great importance in numerous industries. Current state-of-the-art graph neural
4,paper matching is a crucial step of peer review process for venues receiving thousands of submissions . common paper matching algorithms often construct matchings suffering from two critical problems . fairness is a key factor in determining whether a paper,"Paper matching algorithms often result in reviewer groups lacking expertise or highly skewed workloads. To address these issues, this paper proposes a novel local fairness formulation for paper matching. The FairIr and FairFlow algorithms are introduced to compute fair matchings under this formulation. FairIr maximizes the objective under provable fairness constraints, while FairFlow efficiently approximates fairness while prioritizing efficiency. Empirical evaluations show that both algorithms improve fairness compared to standard matching methods, and FairFlow achieves a balance between fairness and efficiency.","This paper introduces FairIr and FairFlow, two algorithms designed to improve the fairness of reviewer-paper matchings in peer reviews by addressing expertise sufficiency and workload skewness. FairIr, using a rounding technique, guarantees objective maximization and minimal fairness compromise, while FairFlow offers greater efficiency without a fairness guarantee, both showing improved performance on real conference data compared to existing methods.","This paper introduces a novel local fairness formulation for paper matching to address reviewer expertise and workload imbalance issues. Two new algorithms, FairIr and FairFlow, are proposed to compute fair matchings efficiently. FairIr maximizes the objective while compromising fairness slightly, while FairFlow is faster and more efficient, improving fairness in real conference data.","Paper Matching with Local Fairness ConstraintsABSTRACT: A novel local fairness formulation for paper matchingAutomatically matching reviewers to papers is a crucial step of the peer review process for venues receiving thousands of submissions. Unfortunately, common"
5,WSDM 2021 tutorial on systemic challenges in peer review . tutorial will discuss a number of systemic challenges in peer review .,"Peer review in scientific research faces systemic challenges including bias, subjectivity, and dishonesty, which are compounded by the growing volume of submissions. This tutorial will delve into these issues with experiments and computational solutions, highlighting open problems with potential impact for the WSDM audience. By addressing these challenges, we can improve the fairness and credibility of peer review, ensuring equitable opportunities for all researchers.","The WSDM 2021 tutorial addresses systemic issues in peer review, highlighting biases, subjectivity, and other challenges that affect researchers' careers, particularly the young. It presents experiments and computational solutions to tackle these problems, emphasizing significant potential impacts on the field if these open issues are resolved.","The WSDM 2021 Tutorial on Bias and Unfairness in Peer Review highlights the systemic challenges faced in scientific research peer review, exacerbated by exponential submission growth. Addressing biases, subjectivity, and dishonesty, the tutorial offers experimental insights and computational solutions. Open problems are identified, promising impactful advancements for the academic community.",WSDM 2021 Tutorial on Systemic Challenges and Computational Solutions on Bias and Unfairness in Peer ReviewABSTRACT: “Peer review is the backbone of scientific research. Yet peer review is called “biased
6,a survey of the peer-review process is conducted on the reviewer assignment problem . the issue directly influences the quality of the publication .,"Automatic approaches to Reviewer Assignment Problem (RAP) in academic peer-review are surveyed. RAP is divided into three phases: candidate search, matching computation, and assignment optimization. Current research primarily focuses on one or two phases, despite their interrelation. The survey categorizes approaches by discipline, highlighting strengths and limitations. Gaps between current methods and practical needs are identified, indicating potential research areas such as integrated and online optimization.","This paper surveys automatic approaches to the Reviewer Assignment Problem (RAP) in academic peer-review, crucial for ensuring publication quality. It categorizes RAP into three interconnected phases—reviewer search, match computation, and assignment optimization—across disciplines like AI and operations research, highlighting current gaps and future research opportunities.","This paper explores the Reviewer Assignment Problem (RAP) in academic peer-review, crucial for publication quality and scientific credibility. It surveys automatic approaches in literature, dividing RAP into three phases: reviewer search, matching computation, and assignment optimization. Current research focuses on individual phases, highlighting interdisciplinary methodologies and future research opportunities for integrated and online optimization.",A COMPREHENSIVE SURVEY OF THE REVIEWER ASSIGNMENT PROBLEMReviewer Assignment Problem (RAP) is an important issue in peer-review of academic writing. This issue directly influences the quality of
7,"survey provides a comprehensive review of the primary research achievements on reviewer assignment algorithm . from 1992 to 2022, the survey discusses the background and necessity of automatic reviewer assignment .","In this survey, we provide a comprehensive review of reviewer assignment algorithms for peer review automation. We discuss the background, necessity, and existing research on constructing candidate reviewer databases, computing matching degrees, and optimizing reviewer assignment algorithms. We also summarize evaluation metrics, datasets, and potential future research directions in this field, serving as a valuable reference for researchers and peer review organizers.","This survey provides an extensive review of advancements in reviewer assignment algorithms from 1992 to 2022, highlighting the importance of matching papers to appropriate reviewers for fair and accurate peer review. It covers the development of reviewer databases, matching computations, and optimization algorithms, offering insights into their pros and cons, and suggests future research directions.","This survey reviews advancements in reviewer assignment algorithms from 1992 to 2022, emphasizing the importance of accurate and fair peer review results. It covers candidate reviewer database construction, matching degree computation, and optimization algorithms, with insights on strengths and weaknesses. The paper also outlines evaluation metrics, datasets, and future research prospects, serving as a valuable reference for researchers and peer review organizers.","Reviewer assignment algorithms for peer review automation: A surveyAssigning paper to suitable reviewers is of great significance to ensure the accuracy and fairness of peer review results. In the past three decades, many researchers have made a wealth of achievements on the"
8,generative probabilistic models are used to model experts' knowledge . the second strategy locates documents on topic and finds the associated expert .,"Two formal models are presented for identifying experts within an organization's document corpus. The models use probabilistic generative techniques to establish connections between experts and documents. The first model connects experts directly to documents, while the second identifies documents on a specific topic and then matches them to experts. The evaluation using the TREC Enterprise corpus shows the superiority of the second model and its strong performance against other unsupervised techniques.","This abstract discusses two generative probabilistic models for expert finding within enterprise document repositories. The first model assesses experts based on associated documents, while the second identifies topical documents before pinpointing experts. Evaluations using the TREC Enterprise corpora demonstrate the superior performance of the second model, especially against other unsupervised methods.","This study introduces two formal strategies for expert finding in enterprise document repositories using generative probabilistic models. The first strategy models an expert's knowledge based on associated documents, while the second locates documents on topic and then identifies the expert. Evaluation on TREC Enterprise corpora demonstrates the superior performance of the second strategy over the first and other unsupervised techniques.",Formal Models for Expert Finding in Enterprise CorporaABSTRACTSearching an organization’s document repositories for experts provides a cost effective solution for the task of expert finding. We present two general strategies to expert searching given a document
9,a (randomized) algorithm for reviewer assignment can optimally solve the reviewer-assignment problem . the algorithm can limit the chance that any malicious reviewer gets assigned to their desired paper to 50% .,"This study presents a framework and randomized algorithm for reviewer assignment in peer review to mitigate manipulation (malicious reviewer assignment, ""torpedo reviewing,"" and reviewer de-anonymization). The algorithm optimally solves the reviewer-assignment problem, considering constraints on reviewer-paper assignment probabilities. The problem of restricting joint probabilities for specific reviewer-paper pairs is investigated, and an efficient solution is provided for a practical special case. Experimental evaluations show that the algorithms effectively limit malicious reviewer assignments while maintaining high assignment quality.","This research addresses three major issues in conference peer review: malicious reviewer assignments, torpedo reviewing, and reviewer de-anonymization. It introduces a randomized algorithm that optimally assigns reviewers under specific constraints, effectively reducing the influence of biased reviews while maintaining high assignment quality, as demonstrated in tests on past conference data.","A novel algorithm for randomized reviewer assignments effectively tackles manipulation in conference peer review, addressing issues like biased positive reviews, torpedo reviewing, and reviewer de-anonymization. The algorithm optimally assigns reviewers to papers while limiting the chance of malicious behavior, achieving over 90% optimal similarity in experimental evaluations.","Mitigating Manipulation in Peer Review via Randomized Reviewer AssignmentsAbstract:IntroductionWe consider three important challenges in conference peer review: (i) reviewers maliciously attempting to get assigned to certain papers to provide positive reviews, possibly"
10,a new approach is proposed to guide the disentangled representation learning . the model is based on a knowledge graph (KG) that is incorporated into recommender systems .,Knowledge-Guided Disentangled Representation Learning (KDR) incorporates knowledge graphs to guide disentangled representation learning in recommender systems. KDR enhances interpretability and addresses data sparsity by aligning implicit disentangled representations from user-item interactions with explicit disentangled representations derived from the KG. The fusion of these representations improves recommendation performance and facilitates understanding the underlying factors influencing user preferences.,"The study introduces a novel Knowledge-guided Disentangled Representations (KDR) approach for recommender systems, leveraging knowledge graphs (KG) to enhance interpretability and address data sparsity in disentangled representation learning. KDR aligns user-item interaction data with KG-structured data using a mutual information maximization strategy, significantly improving recommendation performance and interpretability, as validated by experiments on real-world datasets.","This study explores leveraging knowledge graphs to guide disentangled representation learning in recommender systems. By aligning explicit disentangled representations from the knowledge graph with implicit ones from user-item interactions, a novel approach improves interpretability and addresses data sparsity. Experimental results validate the effectiveness of this Knowledge-guided Disentangled Representations (KDR) model.","Knowledge-Guided Disentangled Representation Learning for Recommender SystemsIn recommender systems, it is essential to understand the underlying factors that affect user-item interaction. Recently, several studies have utilized disentangled representation learning to"
11,a recommender system of reviewers and experts in reviewing problems . the text does not include the content of the abstract from the research paper .,"I'm sorry, I cannot provide a summary of the text without the abstract or additional parts of the document.","The text provided lacks substantive content from the research paper, focusing instead on bibliographic details, publication information, and manuscript status. It does not contain an abstract or any specific insights into the recommender system for reviewers and experts in reviewing problems. Please provide the abstract or relevant sections for a detailed summary.","Summary: The text lacks the abstract but mentions bibliographic details and publication status. It focuses on a recommender system for reviewers and experts in reviewing problems. For a comprehensive summary, additional content such as the abstract is needed to provide insights into the research paper's key findings and contributions.","A recommender system of reviewers and experts in reviewing problemsThe text provided does not include the content of the abstract from the research paper. It only contains bibliographic information, publication details, and a general note about the manuscript's status"
12,a rule-based approach called SAFE was proposed to automatically extract app features from user reviews . the procedure used to evaluate SAFE was in part subjective and not repeatable . the goal of our study is to perform an external,"A replication study of the SAFE approach for app feature extraction from user reviews reveals lower precision and recall than the original study. The evaluation was conducted objectively and repeatably, using multiple review datasets and an accurate implementation of SAFE. The results indicate that SAFE's performance is affected by the density of annotated app features in the review dataset.","This study replicates the evaluation of the SAFE approach, originally designed for extracting app features from user reviews, using a more objective and repeatable method. Implementing SAFE, the researchers found lower precision and recall rates than previously reported, suggesting the approach's effectiveness varies with feature density in datasets. The study emphasizes unbiased, reproducible research by sharing its implementation and datasets.","This study questions the reliability of the SAFE approach for app feature extraction from user reviews. By conducting an objective replication, the researchers found lower precision and recall rates than initially reported. Their unbiased evaluation highlights the impact of feature density on performance, emphasizing the need for reproducible evaluation methods in this field.",Is the SAFE Approach Too Simple for App Feature Extraction? A Replication Study[Context and motivation] Automatic extraction and analysis of app features from user reviews is helpful for software developers to better understand users' perceptions of delivered app features
13,self-supervised learning holds vast potential to improve recommender systems . the framework builds three graph encoders (one for recommendation) upon the augmented views . iteratively improves each encoder with self-supervision signals,"Self-supervised learning (SSL) has been used to improve recommender systems. However, existing SSL-based methods neglect supervision signals from other nodes. To capture these signals, a socially-aware SSL framework with tri-training is proposed. This framework augments user data with social information and uses three graph encoders for multi-view encoding. Tri-training iteratively improves each encoder with self-supervision signals from other users. Experiments show the effectiveness of the framework in improving recommendation.","The paper introduces a socially-aware self-supervised learning framework for recommender systems, utilizing tri-training to enhance data views with user social information. This method leverages self-supervision from multiple graph encoders to iteratively refine user representations, significantly improving recommendation accuracy, as validated by extensive real-world experiments.","A novel socially-aware self-supervised tri-training framework is proposed to enhance recommender systems by integrating user social information. By leveraging self-supervision signals from other users through tri-training, the framework improves multi-view encoding for recommendation. Extensive experiments confirm the effectiveness of this approach on real-world datasets. Code available at https://github.com/Coder-Yu/QRec.","Socially-Aware Self-Supervised Tri-Training for RecommendationABSTRACTIONSSelf-supervised learning (SSL), which can automatically generate ground-truth samples from raw data, holds vast potential to improve recommender"
14,incorporating knowledge graphs into recommender systems to provide explainable recommendation has attracted much attention . existing studies may suffer from error propagation and weak explainability .,"KR-GCN is a novel knowledge-aware recommendation method that addresses error propagation and weak explainability challenges. It uses transition scores and nucleus sampling to select relevant triples from knowledge paths. By integrating user-item interactions and knowledge graphs into a heterogeneous graph, KR-GCN employs graph convolution network for recommendation and a path-level self-attention mechanism for explainability enhancement. Experiments show its superior performance in both recommendation accuracy and explanation quality.","The 4KR-GCN model integrates knowledge graphs with graph convolution networks to enhance recommender systems, addressing error propagation and weak explainability. It uses a transition-based scoring and nucleus sampling for path selection, and a self-attention mechanism to assess path contributions, significantly outperforming existing models in performance and explainability.","""4KR-GCN introduces Knowledge-Aware Reasoning with Graph Convolution Network for Explainable Recommendation. By integrating knowledge graphs, it addresses challenges of error propagation and weak explainability in recommender systems. Utilizing a transition-based method and nucleus sampling, it improves recommendation performance and explanation diversity. Experimental results demonstrate its superiority over existing methods.""",4KR-GCN: Knowledge-Aware Reasoning with Graph Convolution Network for Explainable RecommendationIncorporating knowledge graphs (KGs) into recommender systems to provide explainable recommendation has attracted much attention recently.
15,discriminative models have received little attention in expert search research . discriminative models have been shown to outperform generative models . proposed framework integrates document evidence and document-candidate associations .,"Discriminative models are proposed for expert search, outperforming generative models. These models integrate document evidence and document-candidate associations, eliminating the need for additional modeling assumptions or effort. Experiments on TREC corpora demonstrate the effectiveness and robustness of the discriminative learning framework.","This paper introduces a relevance-based discriminative learning framework for expert search, which effectively integrates document evidence and document-candidate associations, outperforming traditional generative models. Extensive testing on TREC Enterprise track corpora confirms its superiority in both effectiveness and robustness.","This paper introduces a relevance-based discriminative learning framework for expert search, contrasting generative and discriminative models. The proposed approach seamlessly integrates document evidence and associations without additional assumptions. Extensive experiments on TREC Enterprise track corpora validate the framework's effectiveness and robustness, highlighting its potential in enhancing expert search methodologies.",Discriminative Models of Integrating Document Evidence and Document-Candidate Associations for Expert SearchABSTRACT-based discriminative models for expert searchGenerative models such as statistical language modeling have been widely studied in the task
16,a new neighborhood-based interaction model is proposed for recommendation on heterogeneous graphs . the model is based on a convolutional approach and learns efficiently with fast Fourier transform .,"NIRec, an efficient neighborhood-based interaction model for recommendation on heterogeneous graphs, addresses challenges in existing methods by capturing interactive patterns between nodes through metapath-guided neighborhoods. Formulating interactions convolutionally and utilizing fast Fourier transform enables efficient learning on large networks. NIRec outperforms state-of-the-art approaches in experiments across four heterogeneous graph types, highlighting its effectiveness in leveraging node interactions for improved recommendations.","The paper introduces the Neighborhood-based Interaction Model for Recommendation (NIRec) to enhance HIN-based recommender systems. NIRec addresses the limitations of existing methods by capturing interactive patterns through metapath-guided neighborhoods and efficiently learning complex interactions using convolution and fast Fourier transform, demonstrating superior performance across various heterogeneous graphs.","""Efficient Neighborhood-based Interaction Model (NIRec) addresses challenges in HIN-based recommender systems by capturing interactive patterns between nodes through metapath-guided neighborhoods. Utilizing convolutional formulation and fast Fourier transform, NIRec outperforms existing methods on heterogeneous graphs. This pioneering work highlights the significance of learning interactions in HINs for improved recommendations.""",An Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous GraphThere is an influx of heterogeneous information network (HIN) based recommender systems in recent years since HIN is capable of characterizing complex graphs
17,a word and semantic-based iterative model (WSIM) is proposed to account for the constraints of the reviewer assignment problem . the model uses word features and semantic features to represent reviewers and manuscripts . it also,"The proposed Word and Semantic-based Iterative Model (WSIM) addresses the challenges of reviewer assignment in academic publishing by considering the constraints of incomplete reviewer data and interference from non-manuscript-related papers. WSIM extracts both word and semantic features from reviewers and manuscripts, using an improved similarity metric based on normalized discounted cumulative gain (NDCG) to account for incomplete data. An iterative model is then employed to reduce interference from non-manuscript-related papers, considering the similarity between the manuscript and each reviewer's papers. Evaluations on real datasets demonstrate that WSIM improves recommendation accuracy compared to existing methods.","The paper introduces a word and semantic-based iterative model (WSIM) to enhance reviewer-manuscript matching by addressing data incompleteness and interference from irrelevant papers. Utilizing improved language and topic models, WSIM employs a qualitative similarity metric and iterative filtering, achieving at least a 2.5% accuracy improvement in tests against existing methods.","This paper introduces a word and semantic-based iterative model (WSIM) to enhance reviewer assignment by addressing constraints like incomplete reviewer data and nonmanuscript-related interference. By improving similarity calculations between reviewers and manuscripts using advanced language and topic models, WSIM outperforms existing methods, boosting recommendation accuracy by at least 2.5% on the top 20.",Improved reviewer assignment based on both word and semantic featuresAssigning appropriate reviewers to a manuscript from a pool of candidate reviewers is a common challenge in the academic community. Current word- and semantic-based approaches treat the reviewer assignment problem (R
18,graph learning-driven models have made remarkable progress in the field of recommendation . but their performance may suffer from a significant false negative issue .,"RevGNN, an unsupervised graph contrastive learning model, addresses the ""false negative"" issue in academic reviewer recommendation. It uses a two-stage encoder with Pseudo Neg-Label to approximate review preference, handling the ambiguous nature of unobserved interactions. Experiments show that RevGNN outperforms baselines on three real-world datasets, demonstrating the effectiveness of its components.","The study introduces RevGNN, a graph learning model enhanced by a Pseudo Neg-Label strategy for academic reviewer recommendation, addressing the challenge of ambiguous unobserved interactions. RevGNN, using a dual encoder for knowledge and behavior, significantly outperforms baselines in experiments, proving its effectiveness in handling false negatives in reviewer selection.","RevGNN addresses the challenge of academic reviewer recommendation by enhancing graph contrastive learning with a Pseudo Neg-Label strategy. By tackling the ambiguity of unobserved interactions, RevGNN outperforms baselines in recommending reviewers for academic submissions. The two-stage encoder structure encodes scientific knowledge and behavior, demonstrating superior performance across multiple metrics in real-world datasets.","RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer RecommendationAcquiring reviewers for academic submissions is a challenging recommendation scenario. Recent graph learning-driven models have made remarkable progress in the field of recommendation,"
19,"a new approach to CF is to combine factor and neighborhood models . the models can now be smoothly merged, thereby building a more accurate combined model .","A new approach to recommender systems is proposed, combining latent factor and neighborhood models. The model incorporates both explicit and implicit user feedback, improving accuracy. Additionally, a new evaluation metric is suggested to assess the performance of recommendation methods.","This research introduces a collaborative filtering model that merges latent factor and neighborhood approaches, enhancing accuracy by utilizing both explicit and implicit user feedback. Tested on Netflix data, it outperforms previous models and proposes a new metric for evaluating top-K recommendation tasks.","This study introduces innovations in Collaborative Filtering models for recommender systems. By merging latent factor and neighborhood models, and incorporating explicit and implicit user feedback, a more accurate combined model is built. Tested on Netflix data, the results surpass previous benchmarks. A new evaluation metric is proposed to assess performance in top-K recommendation tasks.",Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering ModelABSTRACT DESCRIPTION: Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF
