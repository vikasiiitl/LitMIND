Related_Work
"In recent years, as the growing field of conversational AI expands, the CoQA challenge has been introduced. This dataset features 127k conversational questions and answers from 8k text-based dialogues across seven diverse domains, aiming to enhance conversational question answering systems. Despite strong model performances, a significant gap remains compared to human benchmarks, highlighting opportunities for further advancements in this area.Tihanyi et al. introduced the FormAI dataset, featuring 112,000 AI-generated C programs labeled with vulnerabilities identified via formal verification using ESBMC. Over half contain vulnerabilities, aiding in the development of AI-based security tools and training LLMs [1]. Orenes-Vera et al. investigated using GPT-4 within the AutoSVA framework to automate SystemVerilog Assertions (SVA) generation for formal property verification (FPV). GPT-4 effectively generates safety properties and identifies bugs, enhancing FPV efficiency and effectiveness [2]. Yang & Wang present AVRE, a system utilizing Large Language Models for formal verification of NextG protocols. It converts protocol descriptions into formal models using cross- and self-attention mechanisms, achieving 95.94% accuracy, surpassing traditional methods in scalability and robustness. [3] Drechsler et al. propose a Formal Specification Level (FSL) using UML/SysML to automate translating natural language specifications into formal models. This approach enhances verification and code generation, addressing the complexity of embedded systems design [4]. Hahn et al. investigate language models' generalization in translating natural language into formal specifications, such as regular expressions and logic. Fine-tuned models outperform existing methods, highlighting efficiency, accessibility, and domain-agnostic capabilities without needing domain-specific reasoning [5]. Yang & Wang propose a framework combining formal methods and fuzz testing to detect vulnerabilities in 5G networks. This approach identifies 53 vulnerabilities, reduces detection complexity, and enhances scalability, specifically in Radio Resource Control processes [6]. Yang et al. introduce a method combining formal verification and fuzz testing to improve 5G security. This approach detected 61 vulnerabilities, including two new ones, efficiently identifying issues across protocols and software. It offers a comprehensive solution for vulnerability auto-discovery. [7] Li Dong & Mirella Lapata propose a novel semantic parsing method using an attention-enhanced encoder-decoder model. It maps natural language to logical forms without hand-crafted features, showing competitive performance and adaptability across various domains and representations [8]. The text discusses using large language models (LLMs) for formal hardware specification, emphasizing their potential to speed up development while highlighting the need for structured applications to maintain precision. It underscores the importance of balancing speed and correctness in hardware design [9]. Wang et al. introduced a versatile 5G testbed for experimental research, featuring AI-driven security and performance enhancements. It supports O-RAN compliance, LTE/NR transitions, and location-aware beamforming, with indoor and outdoor capabilities for areas lacking infrastructure [10]. Banarescu et al. discuss Abstract Meaning Representation (AMR), a semantic language for capturing English sentence meanings. They aim to create a sembank of AMR annotations to advance statistical natural language understanding, akin to the Penn Treebank's impact on parsing. [11] Greshake et al. identified vulnerabilities in LLM-integrated applications through Indirect Prompt Injection attacks, which enable adversaries to manipulate functionalities, execute arbitrary code, and steal data. The study calls for robust defenses to address these emerging security threats [12]. Ouyang et al. investigated the non-determinism of ChatGPT in code generation, finding significant variability in outputs across 829 tasks, even with temperature set to zero. This threatens the reliability of scientific conclusions and requires researchers to address this issue [13]. Dauphinais et al. developed a digital twin framework for 5G security testing, using assembly-level fuzzing to efficiently detect vulnerabilities. Demonstrated on the srsRAN software stack, it enhances security and resilience against zero-day threats in 5G systems [14]. Kande et al. investigate the use of large language models (LLMs) for automating the generation of security-centric hardware assertions. The study evaluates an LLM's ability to produce SystemVerilog assertions from natural language prompts using real-world hardware designs and benchmarks. [15] Saparov & He analyzed large language models (LLMs) using the PRONTOQA dataset, revealing that while LLMs exhibit strong deduction skills, they struggle with proof planning, often relying on the first plausible reasoning path due to unclear reasoning processes [16]. Tihanyi et al. introduced the ESBMC-AI framework, combining Large Language Models with Bounded Model Checking to identify and repair software vulnerabilities. It effectively addresses issues like buffer overflows in C programs, showing potential for CI/CD integration [17]. Krishna et al. introduced RANK GEN, a 1.2B parameter encoder model, enhancing text generation by scoring outputs for coherence and relevance. Using contrastive learning, it outperforms traditional methods, improving continuity and human preference scores across language models [18]. Reddy et al. discuss the CoQA dataset, featuring 127k questions from 8k conversations designed for Conversational Question Answering systems. The dataset emphasizes challenges like coreference and reasoning, with models achieving a 65.4% F1 score, below human performance of 88.8% [19]."
