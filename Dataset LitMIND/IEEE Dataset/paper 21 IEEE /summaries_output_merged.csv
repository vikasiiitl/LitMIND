PDF File Name,Merged Summary
0,"Dumford & Scheirer investigated a white-box backdoor attack on CNNs used in facial recognition, exploiting vulnerabilities by perturbing CNN weights to increase false acceptances without impacting legitimate error rates, underscoring the need for enhanced security measures [1]."
1,"Gu et al. discussed how deep neural networks, vulnerable to backdoor attacks when outsourced for training, can be manipulated by adversaries to misclassify specific inputs. This highlights the need for enhanced verification and inspection of neural networks to mitigate security risks [2]."
2,"Liu et al. discuss Refool, a stealthy backdoor attack on DNNs using natural reflections as triggers, which effectively evade current defenses and achieve high misclassification rates across multiple datasets [3]."
3,"Chen et al. investigated backdoor attacks on deep learning systems, demonstrating that injecting minimal poisoned samples into training sets can achieve over 90% success. These findings underscore the vulnerability of such systems and the critical need for enhanced defenses [4]."
4,"Gongora Svartzman and Ramirez Marquez investigate public transportation disruptions during a 2018 snowstorm on New York's Metro North Railroad, comparing official data and passenger reports using Natural Language Processing and visual analytics [5]."
5,"Qi et al. propose ONION, a novel defense against textual backdoor attacks in deep neural networks, utilizing outlier word detection to protect models like BiLSTM and BERT from various attacks. ONION is effective across all textual backdoor attack scenarios and is available online [6]."
6,"Li et al. investigated how NLP systems are compromised by backdoor attacks using covert triggers like homograph replacement and subtle textual differences. These attacks manipulate tasks such as toxic comment detection and neural machine translation, achieving high success rates while evading detection by human inspectors [7]."
7,"Turner et al. discuss how adversaries inject malicious inputs into training data to control model behavior through backdoor triggers. They present a method using adversarial perturbations and generative models to create stealthy, label-consistent backdoor attacks, making them difficult to detect [8]."
8,"Lucic et al. discuss how crowdsourcing in Intelligent Transportation Systems (ITS) and Vehicular Social Networks (VSN) utilizes mobile, spatial, and passive sensing to improve infrastructure monitoring, navigation, and congestion management [9]."
9,"Dai et al. investigated backdoor attacks on LSTM-based text classification systems, where adversaries inject backdoors via data poisoning, leading to misclassification with specific triggers, achieving a 96% success rate while maintaining overall model performance [10]."
10,"Sun et al. investigated the vulnerability of NLG systems to backdoor attacks, proposing defense strategies for tasks like machine translation and dialog generation. They emphasized the need for further research to secure NLG systems against generating offensive content [11]."
11,"Li et al. introduced DeepPayload, a backdoor attack on deep learning models in mobile apps through neural payload injection, achieving a 93.5% success rate with minimal performance impact, exposing vulnerabilities in 54 apps [12]."
12,"Chen and Dai introduce Backdoor Keyword Identification (BKI) to defend against backdoor attacks in LSTM-based text classification by identifying and removing poisoned samples, enhancing model security across multiple datasets [13]."
13,"Li et al. discuss the vulnerability of NLP models to backdoor attacks, proposing two novel methods: a multistyle transfer-based attack and a paraphrase-based attack, both enhancing invisibility and semantic consistency [14]."
14,"Qi et al. investigated adversarial and backdoor attacks in NLP through text style transfer, revealing that altering text style while preserving content significantly compromises NLP models, with success rates over 90% [15]."
15,"Cheng et al. introduced a novel deep feature space Trojan attack on neural networks, demonstrating effectiveness, stealthiness, controllability, robustness, and evasion of advanced defenses across multiple image classifiers and datasets. Extensive experiments on 9 image classifiers, including ImageNet, showcased the attack's capabilities [16]."
16,"Rakin et al. introduced the Targeted Bit Trojan (TBT), a novel method that inserts a neural Trojan into Deep Neural Networks using bit-flip attacks, achieving high success rates with minimal bit manipulation [17]."
17,"Qi et al. investigated backdoor attacks in NLP, introducing a novel textual backdoor attack using syntactic structures as triggers, achieving nearly 100% success with enhanced invisibility and resistance to defenses, underscoring the severe threat to NLP models [18]."
18,"MÃ©ndez et al. propose a novel methodology using Twitter data and text mining techniques like sentiment analysis and topic modeling to assess public transport user satisfaction in Santiago, providing broader coverage and timely insights compared to traditional surveys [19]."
19,"Kurita et al. discuss ""weight poisoning"" in pre-trained NLP models, where vulnerabilities embedded in model weights create backdoors, affecting predictions post-fine-tuning. They highlight the threat across various tasks and propose defensive strategies against such attacks [20]."
20,"Liu et al. investigated the vulnerability of neural networks to Trojan attacks, highlighting the insertion of malicious triggers during training to manipulate model behavior, emphasizing the importance of defense for network security and reliability [21]."
21,"Shao et al. introduced BDDR, a robust defense against textual backdoor attacks in DNNs, reducing attack success rates by over 90% for word-level and 60% for sentence-level attacks using detection and text reconstruction with a pre-trained BERT model [22]."
22,"Hochreiter & Schmidhuber developed Long Short-Term Memory (LSTM), a gradient-based method addressing challenges in recurrent backpropagation over long intervals, significantly enhancing efficiency and performance in complex tasks with long time lags [23]."
23,Chen et al. investigated improving public service satisfaction by monitoring online reviews and applying sentiment analysis and machine learning in Shanghai's suburb parks. This approach visualizes public satisfaction and aids decision-making in service-oriented governance [24].
24,Pan et al. investigated the Hidden Trigger Backdoor Attack on NLP Models through linguistic style manipulation [25].
